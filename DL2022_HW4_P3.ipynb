{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e892903f34a44f99b69d23a3e79be521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d78780b3a3084cf297aae55cc8108524",
              "IPY_MODEL_74440b2681144bd7a0d348d8c006f2e2",
              "IPY_MODEL_c4adc31c93bd4d02837af0d895578d5f"
            ],
            "layout": "IPY_MODEL_4e85a3429c2e4ef9bddffd5f5a6f5539"
          }
        },
        "d78780b3a3084cf297aae55cc8108524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5897932f7083429b8e3f8f3d39b7fa0c",
            "placeholder": "​",
            "style": "IPY_MODEL_1327b034516240c487379296d7e8f633",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "74440b2681144bd7a0d348d8c006f2e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8f8251f097b4a6793d76eb189cd50e6",
            "max": 1198122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d63632ba0c27470c90d856cbd9d40b37",
            "value": 1198122
          }
        },
        "c4adc31c93bd4d02837af0d895578d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_934099835b0045458d42e9e48be22506",
            "placeholder": "​",
            "style": "IPY_MODEL_c0a7dc4e04fc4a3d901c6a206eda7c01",
            "value": " 1.20M/1.20M [00:01&lt;00:00, 1.07MB/s]"
          }
        },
        "4e85a3429c2e4ef9bddffd5f5a6f5539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5897932f7083429b8e3f8f3d39b7fa0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1327b034516240c487379296d7e8f633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8f8251f097b4a6793d76eb189cd50e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d63632ba0c27470c90d856cbd9d40b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "934099835b0045458d42e9e48be22506": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a7dc4e04fc4a3d901c6a206eda7c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "032999eb2c40402d96532f39c5d5b16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd52bd1a94004932b20a15f021f5ca51",
              "IPY_MODEL_3c7e70e23c3a43639c2b73e9366aac85",
              "IPY_MODEL_bede938b2b3d45da9061a369a86c5657"
            ],
            "layout": "IPY_MODEL_1a15b845c1da4ca083042882f35b9f1d"
          }
        },
        "bd52bd1a94004932b20a15f021f5ca51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da3bdd8af27643dcbb351cece086655e",
            "placeholder": "​",
            "style": "IPY_MODEL_0707df43a57649e6808941329c636b43",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "3c7e70e23c3a43639c2b73e9366aac85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10e585556d74581918eafde84b62649",
            "max": 440,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ecaa51d6bea493d8df5b4411d16416a",
            "value": 440
          }
        },
        "bede938b2b3d45da9061a369a86c5657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c86a801047d4f2aa31729141bbec9f7",
            "placeholder": "​",
            "style": "IPY_MODEL_6a6f9ec811304758b6a1fad7049adedc",
            "value": " 440/440 [00:00&lt;00:00, 14.0kB/s]"
          }
        },
        "1a15b845c1da4ca083042882f35b9f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3bdd8af27643dcbb351cece086655e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0707df43a57649e6808941329c636b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f10e585556d74581918eafde84b62649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ecaa51d6bea493d8df5b4411d16416a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c86a801047d4f2aa31729141bbec9f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a6f9ec811304758b6a1fad7049adedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63230d25ad744a988cf9965fb261ac92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05dc523b4ab94f90b1e4b69bb0037d48",
              "IPY_MODEL_573b324f88434c139edd0adb520777ac",
              "IPY_MODEL_8ed125a0d2f240848d58b6840d957aca"
            ],
            "layout": "IPY_MODEL_76d59e0178eb4ece8947a7a0deb9b79e"
          }
        },
        "05dc523b4ab94f90b1e4b69bb0037d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab635322ce53412797b36048460419f5",
            "placeholder": "​",
            "style": "IPY_MODEL_08735a619d8b497986974ad529ac4f25",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "573b324f88434c139edd0adb520777ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19728a2e6dec455d91284ca0790bd6a3",
            "max": 654226731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68d84e9c5c8a4232a3f6bcd6d33cd092",
            "value": 654226731
          }
        },
        "8ed125a0d2f240848d58b6840d957aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4c6f3b1b3742a68cd9ba11b9c4b3bb",
            "placeholder": "​",
            "style": "IPY_MODEL_bf017f428d094ce6ad18265e42551048",
            "value": " 654M/654M [00:02&lt;00:00, 274MB/s]"
          }
        },
        "76d59e0178eb4ece8947a7a0deb9b79e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab635322ce53412797b36048460419f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08735a619d8b497986974ad529ac4f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19728a2e6dec455d91284ca0790bd6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68d84e9c5c8a4232a3f6bcd6d33cd092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc4c6f3b1b3742a68cd9ba11b9c4b3bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf017f428d094ce6ad18265e42551048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikelroid/DeepLearning_HW4/blob/main/DL2022_HW4_P3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6weydSSPP3ut"
      },
      "source": [
        "# Sentiment Analysis with ParsBERT\n",
        "\n",
        "\n",
        "## BERT Overview\n",
        "\n",
        "BERT stands for Bi-directional Encoder Representation from Transformers is designed to pre-train deep bidirectional representations from unlabeled texts by jointly conditioning on both left and right context in all layers. The pretrained BERT model can be fine-tuned with just one additional output layer (in many cases) to create state-of-the-art models. This model can use for a wide range of NLP tasks, such as question answering and language inference, and so on without substantial task-specific architecture modification.\n",
        "\n",
        "\n",
        "Natural Language Processing (NLP) tasks include sentence-level tasks or token-level tasks:\n",
        "\n",
        "- **Sentence-Level:** Tasks such as Natural Language Inference (NLI) aim to predict the relationships between sentences by holistically analyzing them.\n",
        "- **Token-Level:** Tasks such as Named Entity Recognition (NER), Question Answering (QA), the model makes predictions on a word-by-word basis.\n",
        "\n",
        "In the pre-trained language representation, there are two primary strategies for applying to down-stream NLP tasks:\n",
        "\n",
        "- Feature-based: They use task-specific architectures that include pre-training representation as additional features like Word2vec, ELMo, ...\n",
        "- Fine-tunning: Introduce minimal task-specific parameters, and are trained on the down-stream tasks by merely tuning the pre-training parameters like GPT.\n",
        "\n",
        "Before going more further into code, let me introduce **ParsBERT**.\n",
        "\n",
        "## ParsBERT\n",
        "\n",
        "Is a monolingual language model based on Google's BERT architecture. This model is pre-trained on large Persian corpora with various writing styles from numerous subjects (e.g., scientific, novels, news, ...) with more than **3.9M** documents, **73M** sentences, and **1.3B** words. For more information about ParsBERT, please check out our article: [arXiv:2005.12515](https://arxiv.org/abs/2005.12515).\n",
        "\n",
        "[ParsBERT Repository](https://github.com/hooshvare/parsbert)\n",
        "\n",
        "So, now you have a little understanding of BERT in total, we need to know how to use ParsBERT in our project. In the following tutorial, I would like to implement a fine-tuned model on the Sentiment Analysis task for TensorFlow and PyTorch. Stay tuned!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh7Nx5Okw_2x",
        "outputId": "d06622ae-5ea1-4894-e87a-5a2dd21ceba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUqxg2nSxFn2",
        "outputId": "0615274d-bf32-46ac-cddc-63d132751730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1v5fVXVsjR9cD7hVL0kK69N68E-Traw5Q/HW4\n"
          ]
        }
      ],
      "source": [
        "%cd drive/MyDrive/deep_learning/HW4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/amnghd/Persian_poems_corpus"
      ],
      "metadata": {
        "id": "LV-A1Q3ENLB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from os import walk\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import collections\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.utils import shuffle\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "LQ0euq_Q-ppZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poets = ['jami','moulavi','bahar','salman','farrokhi','naserkhosro','vahshi','khajoo','asadi','saeb']\n",
        "pomes_data = []\n",
        "label = []\n",
        "\n",
        "for i,p in enumerate(poets):\n",
        "  data = open('Persian_poems_corpus/normalized/'+p+'_norm.txt').read()\n",
        "  poems = data.lower().split(\"\\n\")[1:]\n",
        "  for poem in poems:\n",
        "    if len(poem)>6 and '  \\t' != poem :\n",
        "      pomes_data.append(poem)\n",
        "      label.append(poets[i])\n",
        "all_poems = pd.DataFrame({\n",
        "                        \"poem\": pomes_data,\n",
        "                     \"poet\": label})\n",
        "all_poems.to_csv('poems.csv')"
      ],
      "metadata": {
        "id": "vA5Icf3yAbwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_poems = pd.read_csv('poems.csv', usecols= ['poem','poet'])"
      ],
      "metadata": {
        "id": "Jgdls9omSsew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny0D77atzqWT"
      },
      "source": [
        "### Handling Unbalanced Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJXgPOw-zWu2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "c10b8fbd-4bff-48fa-d578-d92721ae630c"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "fig = go.Figure()\n",
        "\n",
        "groupby_label = all_poems.groupby('poet')['poet'].count()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=list(groupby_label.index),\n",
        "    y=groupby_label.tolist(),\n",
        "    text=groupby_label.tolist(),\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Distribution of label within comments [DATA]',\n",
        "    xaxis_title_text='Label',\n",
        "    yaxis_title_text='Frequency',\n",
        "    bargap=0.2,\n",
        "    bargroupgap=0.2)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"de371b1e-ef2a-43a6-8397-1f8cf4766d0b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"de371b1e-ef2a-43a6-8397-1f8cf4766d0b\")) {                    Plotly.newPlot(                        \"de371b1e-ef2a-43a6-8397-1f8cf4766d0b\",                        [{\"text\":[\"17615\",\"41534\",\"23970\",\"66190\",\"17693\",\"52956\",\"21497\",\"15003\",\"26030\",\"20989\"],\"x\":[\"asadi\",\"bahar\",\"farrokhi\",\"jami\",\"khajoo\",\"moulavi\",\"naserkhosro\",\"saeb\",\"salman\",\"vahshi\"],\"y\":[17615,41534,23970,66190,17693,52956,21497,15003,26030,20989],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of label within comments [DATA]\"},\"xaxis\":{\"title\":{\"text\":\"Label\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('de371b1e-ef2a-43a6-8397-1f8cf4766d0b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q0yEPxd-tb-"
      },
      "source": [
        "Again, for making things simple. We cut the dataset randomly based on the fewer label, the negative class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7go47tYozdZI"
      },
      "source": [
        "all_poems = pd.read_csv('poems.csv', usecols= ['poem','poet'])\n",
        "import numpy as np\n",
        "\n",
        "min_lenght = 25000\n",
        "for p in poets:\n",
        "  indxs = all_poems.index[all_poems['poet'] == p].tolist()\n",
        "  lenght = len(indxs)-min_lenght\n",
        "  lenght = int((lenght+np.abs(lenght))/2)\n",
        "  drop_indices = np.random.choice(indxs, lenght, replace=False)\n",
        "  all_poems.drop(drop_indices,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8m5Md-a0KMu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "0c2fab1d-46fe-4947-ffed-ffa757e6f30d"
      },
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "groupby_label = all_poems.groupby('poet')['poet'].count()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=list(groupby_label.index),\n",
        "    y=groupby_label.tolist(),\n",
        "    text=groupby_label.tolist()\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Distribution of label within comments [NEW DATA]',\n",
        "    xaxis_title_text='Label',\n",
        "    yaxis_title_text='Frequency',\n",
        "    bargap=0.2,\n",
        "    bargroupgap=0.2)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"b430772b-6159-407b-9d56-75a969ff4bea\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b430772b-6159-407b-9d56-75a969ff4bea\")) {                    Plotly.newPlot(                        \"b430772b-6159-407b-9d56-75a969ff4bea\",                        [{\"text\":[\"17615\",\"25000\",\"23970\",\"25000\",\"17693\",\"25000\",\"21497\",\"15003\",\"25000\",\"20989\"],\"x\":[\"asadi\",\"bahar\",\"farrokhi\",\"jami\",\"khajoo\",\"moulavi\",\"naserkhosro\",\"saeb\",\"salman\",\"vahshi\"],\"y\":[17615,25000,23970,25000,17693,25000,21497,15003,25000,20989],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"title\":{\"text\":\"Distribution of label within comments [NEW DATA]\"},\"xaxis\":{\"title\":{\"text\":\"Label\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"bargap\":0.2,\"bargroupgap\":0.2},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b430772b-6159-407b-9d56-75a969ff4bea');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NczPnoRI0WPq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "afdf184c-6768-4514-e9c1-b7d085e5f998"
      },
      "source": [
        "all_poems"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          poem  poet\n",
              "6                  الله الله چه طرفه نامست این  jami\n",
              "10               از یدالله چو پنجه اند این پنج  jami\n",
              "11                   زان گرانمایه گنج گوهر سنج  jami\n",
              "15                   جلوه گر صد هزار نعمت کمال  jami\n",
              "17                         جامه مشک رنگ پوشیده  jami\n",
              "...                                        ...   ...\n",
              "303472       چنان در خانه آیینه محو دیدن خویشی  saeb\n",
              "303473  که گر عالم شود زیر و زبر بیرون نمی آیی  saeb\n",
              "303474          چشمی نچراندیم درین باغ چو شبنم  saeb\n",
              "303475           چون سرو فشردیم قدم بر لب جویی  saeb\n",
              "303476          با موی سفید اشک ندامت نفشاندیم  saeb\n",
              "\n",
              "[216767 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbff8bbd-a3af-4248-b933-e77d74e5fcd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>poem</th>\n",
              "      <th>poet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>الله الله چه طرفه نامست این</td>\n",
              "      <td>jami</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>از یدالله چو پنجه اند این پنج</td>\n",
              "      <td>jami</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>زان گرانمایه گنج گوهر سنج</td>\n",
              "      <td>jami</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>جلوه گر صد هزار نعمت کمال</td>\n",
              "      <td>jami</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>جامه مشک رنگ پوشیده</td>\n",
              "      <td>jami</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303472</th>\n",
              "      <td>چنان در خانه آیینه محو دیدن خویشی</td>\n",
              "      <td>saeb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303473</th>\n",
              "      <td>که گر عالم شود زیر و زبر بیرون نمی آیی</td>\n",
              "      <td>saeb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303474</th>\n",
              "      <td>چشمی نچراندیم درین باغ چو شبنم</td>\n",
              "      <td>saeb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303475</th>\n",
              "      <td>چون سرو فشردیم قدم بر لب جویی</td>\n",
              "      <td>saeb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303476</th>\n",
              "      <td>با موی سفید اشک ندامت نفشاندیم</td>\n",
              "      <td>saeb</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216767 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbff8bbd-a3af-4248-b933-e77d74e5fcd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbff8bbd-a3af-4248-b933-e77d74e5fcd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbff8bbd-a3af-4248-b933-e77d74e5fcd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpLObddZROJm"
      },
      "source": [
        "## Train,Validation,Test split\n",
        "\n",
        "To achieve a globalized model, we need to split the cleaned dataset into train, valid, test sets due to size of the data. In this tutorial, I have considered a rate of **0.1** for both *valid*, *test* sets. For splitting, I use `train_test_split` provided by Sklearn package with stratifying on the label for preserving the distribution balance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR_4CTGERLyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6753d492-8507-4374-b712-35cd80f07132"
      },
      "source": [
        "all_poems['poet_ids'] = all_poems['poet'].apply(lambda t: poets.index(t))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(all_poems, test_size=0.1, random_state=1, stratify=all_poems['poet'])\n",
        "train, valid = train_test_split(train, test_size=0.1, random_state=1, stratify=train['poet'])\n",
        "\n",
        "train = train.reset_index(drop=True)\n",
        "valid = valid.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n",
        "perplexity_set = test.sample(n=1000)\n",
        "\n",
        "x_train, y_train = train['poem'].values.tolist(), train['poet_ids'].values.tolist()\n",
        "x_valid, y_valid = valid['poem'].values.tolist(), valid['poet_ids'].values.tolist()\n",
        "x_test, y_test = test['poem'].values.tolist(), test['poet_ids'].values.tolist()\n",
        "x_perplexity, y_perplexity = perplexity_set['poem'].values.tolist(), perplexity_set['poet_ids'].values.tolist()\n",
        "\n",
        "print(train.shape)\n",
        "print(valid.shape)\n",
        "print(test.shape)\n",
        "print(perplexity_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(175581, 3)\n",
            "(19509, 3)\n",
            "(21677, 3)\n",
            "(1000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjfRss-DR3fu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a32b9c-42c4-4cf5-f12c-00fbf2f7a3ff"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertConfig, BertTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SperdZDDWKxT"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFpUoggdpU3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1eeb210-23fd-4ce0-f40f-f3970620e7ef"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda:0\n",
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH38OJU0X7rd"
      },
      "source": [
        "TRAIN_BATCH_SIZE = 64\n",
        "VALID_BATCH_SIZE = 64\n",
        "TEST_BATCH_SIZE = 64\n",
        "\n",
        "EEVERY_EPOCH = 1000\n",
        "CLIP = 0.0\n",
        "\n",
        "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
        "OUTPUT_PATH = '/model/bert-fa-base-uncased.bin'\n",
        "\n",
        "import os\n",
        "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK02AC0pYIPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42958b1b-f417-440c-86fc-e362a332ca72"
      },
      "source": [
        "label2id = {label: i for i, label in enumerate(poets)}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "\n",
        "print(f'label2id: {label2id}')\n",
        "print(f'id2label: {id2label}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label2id: {'jami': 0, 'moulavi': 1, 'bahar': 2, 'salman': 3, 'farrokhi': 4, 'naserkhosro': 5, 'vahshi': 6, 'khajoo': 7, 'asadi': 8, 'saeb': 9}\n",
            "id2label: {0: 'jami', 1: 'moulavi', 2: 'bahar', 3: 'salman', 4: 'farrokhi', 5: 'naserkhosro', 6: 'vahshi', 7: 'khajoo', 8: 'asadi', 9: 'saeb'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGJRNBXFYOcx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e892903f34a44f99b69d23a3e79be521",
            "d78780b3a3084cf297aae55cc8108524",
            "74440b2681144bd7a0d348d8c006f2e2",
            "c4adc31c93bd4d02837af0d895578d5f",
            "4e85a3429c2e4ef9bddffd5f5a6f5539",
            "5897932f7083429b8e3f8f3d39b7fa0c",
            "1327b034516240c487379296d7e8f633",
            "c8f8251f097b4a6793d76eb189cd50e6",
            "d63632ba0c27470c90d856cbd9d40b37",
            "934099835b0045458d42e9e48be22506",
            "c0a7dc4e04fc4a3d901c6a206eda7c01",
            "032999eb2c40402d96532f39c5d5b16f",
            "bd52bd1a94004932b20a15f021f5ca51",
            "3c7e70e23c3a43639c2b73e9366aac85",
            "bede938b2b3d45da9061a369a86c5657",
            "1a15b845c1da4ca083042882f35b9f1d",
            "da3bdd8af27643dcbb351cece086655e",
            "0707df43a57649e6808941329c636b43",
            "f10e585556d74581918eafde84b62649",
            "4ecaa51d6bea493d8df5b4411d16416a",
            "7c86a801047d4f2aa31729141bbec9f7",
            "6a6f9ec811304758b6a1fad7049adedc"
          ]
        },
        "outputId": "2504d3bb-6d6f-4b08-af3a-bb05eade36f7"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "config = BertConfig.from_pretrained(\n",
        "    MODEL_NAME_OR_PATH, **{\n",
        "        'label2id': label2id,\n",
        "        'id2label': id2label,\n",
        "    })\n",
        "\n",
        "#print(config.to_json_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e892903f34a44f99b69d23a3e79be521"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/440 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "032999eb2c40402d96532f39c5d5b16f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr9L9N91gSpm"
      },
      "source": [
        "### Input Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygnLJu8uhjPT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3c2378e-4fb4-43d4-d786-187c145321e2"
      },
      "source": [
        "l = []\n",
        "from tqdm import tqdm\n",
        "for id in tqdm(range(len(all_poems))):\n",
        "  sample_poem = all_poems.iloc[id]['poem']\n",
        "  sample_label = all_poems.iloc[id]['poet']\n",
        "  tokens = tokenizer.tokenize(sample_poem)\n",
        "  l.append(len(tokens))\n",
        "  \n",
        "ll = np.array(l)\n",
        "j = np.argmax(ll)\n",
        "print(max(l))\n",
        "MAX_LEN = max(l)+2\n",
        "\n",
        "sample_poem = all_poems.iloc[j]['poem']\n",
        "sample_label = all_poems.iloc[j]['poet']\n",
        "tokens = tokenizer.tokenize(sample_poem)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f'  Poet: {sample_poem}')\n",
        "print(f'   Tokens: {tokenizer.convert_tokens_to_string(tokens)}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 216767/216767 [02:16<00:00, 1590.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15\n",
            "  Poet: نه از خاکم و نه از بادم نه از آتش و نه از آبم\n",
            "   Tokens: نه از خاکم و نه از بادم نه از اتش و نه از ابم\n",
            "Token IDs: [3254, 2791, 4361, 2015, 1379, 3254, 2791, 23820, 3254, 2791, 4662, 1379, 3254, 2791, 51815]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgsgZ2b5h2I4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f17b6759-12ee-40a2-cc56-882b674df37e"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "    sample_poem,\n",
        "    max_length=MAX_LEN,\n",
        "    truncation=True,\n",
        "    add_special_tokens=True,\n",
        "    return_token_type_ids=True,\n",
        "    return_attention_mask=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt',\n",
        ")\n",
        "\n",
        "print(f'Keys: {encoding.keys()}\\n')\n",
        "for k in encoding.keys():\n",
        "    print(f'{k}:\\n{encoding[k]}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
            "\n",
            "input_ids:\n",
            "tensor([[    2,  3254,  2791,  4361,  2015,  1379,  3254,  2791, 23820,  3254,\n",
            "          2791,  4662,  1379,  3254,  2791, 51815,     4]])\n",
            "token_type_ids:\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
            "attention_mask:\n",
            "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr8cRm9xiyKh"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaJBSSuMizgr"
      },
      "source": [
        "class PoemseDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, tokenizer, poems, targets=None, poets=None, max_len=128):\n",
        "        self.poems = poems\n",
        "        self.targets = targets\n",
        "        self.has_target = isinstance(targets, list) or isinstance(targets, np.ndarray)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.label_map = {label: i for i, label in enumerate(poets)} if isinstance(poets, list) else {}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.poems)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        poems = str(self.poems[item])\n",
        "\n",
        "        if self.has_target:\n",
        "            target = self.label_map.get(str(self.targets[item]), str(self.targets[item]))\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            poems,\n",
        "            add_special_tokens=True,\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=True,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt')\n",
        "        \n",
        "        inputs = {\n",
        "            'poem': poems,\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'token_type_ids': encoding['token_type_ids'].flatten(),\n",
        "        }\n",
        "\n",
        "        if self.has_target:\n",
        "            inputs['targets'] = torch.tensor(target, dtype=torch.long)\n",
        "        \n",
        "        return inputs\n",
        "\n",
        "\n",
        "def create_data_loader(x, y, tokenizer, max_len, batch_size, poets):\n",
        "    dataset = PoemseDataset(\n",
        "        poems=x,\n",
        "        targets=y,\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len, \n",
        "        poets=poets)\n",
        "    \n",
        "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEcefj6fkZFl"
      },
      "source": [
        "\n",
        "train_data_loader = create_data_loader(train['poem'].to_numpy(), train['poet'].to_numpy(), tokenizer, MAX_LEN, TRAIN_BATCH_SIZE, poets)\n",
        "valid_data_loader = create_data_loader(valid['poem'].to_numpy(), valid['poet'].to_numpy(), tokenizer, MAX_LEN, VALID_BATCH_SIZE, poets)\n",
        "test_data_loader = create_data_loader(test['poem'].to_numpy(), None, tokenizer, MAX_LEN, TEST_BATCH_SIZE, poets)\n",
        "perplexity_data_loader = create_data_loader(perplexity_set['poem'].to_numpy(), perplexity_set['poet'].to_numpy(), tokenizer, MAX_LEN, TEST_BATCH_SIZE, poets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qSxzPU2krDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5a6302-1080-412a-bb0b-28f1eb168b91"
      },
      "source": [
        "sample_data = next(iter(train_data_loader))\n",
        "\n",
        "print(sample_data.keys())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['poem', 'input_ids', 'attention_mask', 'token_type_ids', 'targets'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mv75ARn_R_Dt"
      },
      "source": [
        "class SentimentModel(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(SentimentModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(MODEL_NAME_OR_PATH)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, 10)\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        \n",
        "        pooled_output = self.bert(\n",
        "            input_ids=input_ids, \n",
        "            attention_mask=attention_mask, \n",
        "            token_type_ids=token_type_ids)['pooler_output']\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e044fZSfBoKe"
      },
      "source": [
        "\n",
        "\n",
        "def simple_accuracy(y_true, y_pred):\n",
        "    return (y_true == y_pred).mean()\n",
        "\n",
        "def acc_and_f1(y_true, y_pred, average='weighted'):\n",
        "    acc = simple_accuracy(y_true, y_pred)\n",
        "    f1 = f1_score(y_true=y_true, y_pred=y_pred, average=average)\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "    }\n",
        "\n",
        "def y_loss(y_true, y_pred, losses):\n",
        "    y_true = torch.stack(y_true).cpu().detach().numpy()\n",
        "    y_pred = torch.stack(y_pred).cpu().detach().numpy()\n",
        "    y = [y_true, y_pred]\n",
        "    loss = np.mean(losses)\n",
        "\n",
        "    return y, loss\n",
        "\n",
        "\n",
        "def eval_op(model, data_loader, loss_fn,epoch):\n",
        "    model.eval()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    with torch.no_grad(),tqdm(data_loader, total=len(data_loader)) as pbar:\n",
        "        for i,dl in enumerate(pbar):\n",
        "            \n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "            targets = dl['targets']\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "\n",
        "            outputs = model(input_ids,attention_mask,token_type_ids)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred.extend(preds)\n",
        "            y_true.extend(targets)\n",
        "            eval_y, _ = y_loss(y_true, y_pred, losses)\n",
        "            eval_acc = acc_and_f1(eval_y[0], eval_y[1], average='weighted')['acc']\n",
        "            pbar.set_description(f'VALID EPOCH : {epoch} - Loss: {sum(losses)/(i+1):.4f} - Accuracy: {eval_acc*100:.2f}%')\n",
        "    \n",
        "    eval_y, eval_loss = y_loss(y_true, y_pred, losses)\n",
        "    return eval_y, eval_loss\n",
        "\n",
        "\n",
        "def train_op(model, data_loader, loss_fn, optimizer, scheduler,epoch):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "\n",
        "    with tqdm(data_loader, total=len(data_loader)) as pbar:\n",
        "       for i,dl in enumerate(pbar):\n",
        "\n",
        "          input_ids = dl['input_ids']\n",
        "          attention_mask = dl['attention_mask']\n",
        "          token_type_ids = dl['token_type_ids']\n",
        "          targets = dl['targets']\n",
        "\n",
        "          input_ids = input_ids.to(device)\n",
        "          attention_mask = attention_mask.to(device)\n",
        "          token_type_ids = token_type_ids.to(device)\n",
        "          targets = targets.to(device)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(input_ids=input_ids,attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "          \n",
        "          _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "          loss = loss_fn(outputs, targets)\n",
        "          losses.append(loss.item())\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          optimizer.step()\n",
        "          scheduler.step()\n",
        "\n",
        "          y_pred.extend(preds)\n",
        "          y_true.extend(targets)\n",
        "          train_y, _ = y_loss(y_true, y_pred, losses)\n",
        "          train_acc = acc_and_f1(train_y[0], train_y[1], average='weighted')['acc']\n",
        "          pbar.set_description(f'TRAIN EPOCH : {epoch} - Loss: {sum(losses)/(i+1):.4f} - Accuracy: {train_acc*100:.2f}%')\n",
        "\n",
        "    train_y, train_loss = y_loss(y_true, y_pred, losses)\n",
        "    \n",
        "    return train_y, train_loss, eval_loss_min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, comments, tokenizer, max_len=MAX_LEN, batch_size=TEST_BATCH_SIZE):\n",
        "    data_loader = create_data_loader(comments, None, tokenizer, max_len, batch_size, None)\n",
        "    \n",
        "    predictions = []\n",
        "    prediction_probs = []\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for dl in tqdm(data_loader, position=0):\n",
        "            input_ids = dl['input_ids']\n",
        "            attention_mask = dl['attention_mask']\n",
        "            token_type_ids = dl['token_type_ids']\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            token_type_ids = token_type_ids.to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                token_type_ids=token_type_ids)\n",
        "\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "            predictions.extend(preds)\n",
        "            prediction_probs.extend(F.softmax(outputs, dim=1))\n",
        "\n",
        "    predictions = torch.stack(predictions).cpu().detach().numpy()\n",
        "    prediction_probs = torch.stack(prediction_probs).cpu().detach().numpy()\n",
        "\n",
        "    return predictions, prediction_probs"
      ],
      "metadata": {
        "id": "x8j28ZXl0QBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART A :**\n",
        "Train a model just by train classifier model."
      ],
      "metadata": {
        "id": "wm-r-gWQgIER"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07WUk4YHgB0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bae59a1-4d09-4727-b563-0f877f9c5600"
      },
      "source": [
        "A_model = SentimentModel(config).to(device)\n",
        "print('pt_model', type(A_model))\n",
        "\n",
        "for param in A_model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "params_to_update = []\n",
        "for name,param in A_model.named_parameters():\n",
        "    if 'classifier' in name :\n",
        "        param.requires_grad = True\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_model <class '__main__.SentimentModel'>\n",
            "\t classifier.weight\n",
            "\t classifier.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quUTuJDOgB0c"
      },
      "source": [
        "sample_data_poem = sample_data['poem']\n",
        "sample_data_input_ids = sample_data['input_ids'].to(device)\n",
        "sample_data_attention_mask = sample_data['attention_mask'].to(device)\n",
        "sample_data_token_type_ids = sample_data['token_type_ids'].to(device)\n",
        "sample_data_targets = sample_data['targets'].to(device)\n",
        "\n",
        "outputs = A_model(sample_data_input_ids, sample_data_attention_mask, sample_data_token_type_ids)\n",
        "_, preds = torch.max(outputs, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-5"
      ],
      "metadata": {
        "id": "yWTWM8rQgB0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#A_model.load_state_dict(torch.load(\"Poet_classification_last_layer_tune.pth\"),strict = False)"
      ],
      "metadata": {
        "id": "IrL4gWkOgB0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbwsijpygB0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "357771e6-dd35-4cfe-d5df-6026a51063d6"
      },
      "source": [
        "optimizer = torch.optim.AdamW(params_to_update, lr=LEARNING_RATE)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "eval_loss_min = np.Inf\n",
        "history = collections.defaultdict(list)\n",
        "\n",
        "ls = []\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  \n",
        "    train_y, train_loss, eval_loss_min = train_op(A_model, train_data_loader, loss_fn, optimizer, scheduler,epoch)\n",
        "\n",
        "    train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "    \n",
        "    eval_y, eval_loss = eval_op(A_model, valid_data_loader, loss_fn,epoch)\n",
        "    ls.append(eval_loss)\n",
        "    if (ls[-1]==min(ls)):\n",
        "          torch.save(A_model.state_dict(), 'Poet_classification_last_layer_tune.pth')\n",
        "    eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "    \n",
        "    history['train_acc'].append(train_score['acc'])\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(eval_score['acc'])\n",
        "    history['val_loss'].append(eval_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN EPOCH : 1 - Loss: 2.2673 - Accuracy: 14.13%: 100%|██████████| 2744/2744 [15:39<00:00,  2.92it/s]\n",
            "VALID EPOCH : 1 - Loss: 2.2271 - Accuracy: 18.31%: 100%|██████████| 305/305 [00:33<00:00,  9.08it/s]\n",
            "TRAIN EPOCH : 2 - Loss: 2.2236 - Accuracy: 17.23%: 100%|██████████| 2744/2744 [15:40<00:00,  2.92it/s]\n",
            "VALID EPOCH : 2 - Loss: 2.1926 - Accuracy: 20.70%: 100%|██████████| 305/305 [00:32<00:00,  9.37it/s]\n",
            "TRAIN EPOCH : 3 - Loss: 2.1990 - Accuracy: 19.06%: 100%|██████████| 2744/2744 [15:37<00:00,  2.93it/s]\n",
            "VALID EPOCH : 3 - Loss: 2.1713 - Accuracy: 21.97%: 100%|██████████| 305/305 [00:32<00:00,  9.36it/s]\n",
            "TRAIN EPOCH : 4 - Loss: 2.1833 - Accuracy: 19.82%: 100%|██████████| 2744/2744 [15:37<00:00,  2.93it/s]\n",
            "VALID EPOCH : 4 - Loss: 2.1567 - Accuracy: 22.72%: 100%|██████████| 305/305 [00:32<00:00,  9.45it/s]\n",
            "TRAIN EPOCH : 5 - Loss: 2.1712 - Accuracy: 20.61%: 100%|██████████| 2744/2744 [15:31<00:00,  2.95it/s]\n",
            "VALID EPOCH : 5 - Loss: 2.1464 - Accuracy: 23.13%: 100%|██████████| 305/305 [00:33<00:00,  9.15it/s]\n",
            "TRAIN EPOCH : 6 - Loss: 2.1651 - Accuracy: 20.90%: 100%|██████████| 2744/2744 [15:35<00:00,  2.93it/s]\n",
            "VALID EPOCH : 6 - Loss: 2.1392 - Accuracy: 23.52%: 100%|██████████| 305/305 [00:32<00:00,  9.41it/s]\n",
            "TRAIN EPOCH : 7 - Loss: 2.1599 - Accuracy: 21.15%: 100%|██████████| 2744/2744 [15:33<00:00,  2.94it/s]\n",
            "VALID EPOCH : 7 - Loss: 2.1340 - Accuracy: 23.82%: 100%|██████████| 305/305 [00:33<00:00,  9.05it/s]\n",
            "TRAIN EPOCH : 8 - Loss: 2.1551 - Accuracy: 21.44%:  46%|████▌     | 1268/2744 [04:11<04:52,  5.04it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-f8a036982e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_loss_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc_and_f1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-8ded4c8b5158>\u001b[0m in \u001b[0;36mtrain_op\u001b[0;34m(model, data_loader, loss_fn, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-124a332d357d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         pooled_output = self.bert(\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         )\n\u001b[0;32m-> 1019\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    607\u001b[0m                 )\n\u001b[1;32m    608\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    610\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         )\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12dl1xukgB0d"
      },
      "source": [
        "test_poems = test['poem'].to_numpy()\n",
        "preds, probs = predict(A_model, test_poems, tokenizer, max_len=MAX_LEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVLj6jDegB0d"
      },
      "source": [
        "y_test, y_pred = [poets.index(label) for label in test['poet'].values], list(preds)\n",
        "print(f'F1 score: {f1_score(y_test, y_pred, average=\"weighted\"):.4f}')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
        "print(f'Loss: {loss_fn(torch.tensor(probs),torch.tensor(y_test)).item()}')\n",
        "print()\n",
        "print(classification_report(y_test, y_pred, target_names=poets))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm,display_labels=poets)\n",
        "fig, ax = plt.subplots(figsize=(20,20))\n",
        "ax.set_title('Confusion Matrix for Train last layer',fontweight=\"bold\", size=40)\n",
        "ax.set_ylabel('Pred',fontweight=\"bold\", fontsize = 20.0)\n",
        "ax.set_xlabel('True',fontweight=\"bold\", fontsize = 20) \n",
        "disp.plot(ax=ax)\n"
      ],
      "metadata": {
        "id": "mrzpd5qSgB0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART B1 :**\n",
        "Fine-tune whole model, by adam algorithm"
      ],
      "metadata": {
        "id": "oxURFIqAgdOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = [0,0,0]"
      ],
      "metadata": {
        "id": "UqvwtHcy290X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vzQGZGUmw3-"
      },
      "source": [
        "pt_model = SentimentModel(config).to(device)\n",
        "print('pt_model', type(pt_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68gIBEpiqBZc"
      },
      "source": [
        "sample_data_poem = sample_data['poem']\n",
        "sample_data_input_ids = sample_data['input_ids'].to(device)\n",
        "sample_data_attention_mask = sample_data['attention_mask'].to(device)\n",
        "sample_data_token_type_ids = sample_data['token_type_ids'].to(device)\n",
        "sample_data_targets = sample_data['targets'].to(device)\n",
        "\n",
        "outputs = pt_model(sample_data_input_ids, sample_data_attention_mask, sample_data_token_type_ids)\n",
        "_, preds = torch.max(outputs, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-4"
      ],
      "metadata": {
        "id": "aKHwPg-eBlmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(pt_model.parameters(), lr=LEARNING_RATE)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "eval_loss_min = np.Inf\n",
        "history = collections.defaultdict(list)\n",
        "_, perple_loss = eval_op(pt_model, perplexity_data_loader, loss_fn,epoch)\n",
        "perplexity[0] = (torch.exp(torch.tensor(perple_loss)))"
      ],
      "metadata": {
        "id": "-2QPvDnC3Ov6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_model.load_state_dict(torch.load(\"Poet_classification_Adam_finetune.pth\"),strict = False)"
      ],
      "metadata": {
        "id": "NHllYe9xLRNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTWrdialDAtN"
      },
      "source": [
        "ls = []\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_y, train_loss, eval_loss_min = train_op(pt_model, train_data_loader, loss_fn, optimizer, scheduler,epoch)\n",
        "    train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "    eval_y, eval_loss = eval_op(pt_model, valid_data_loader, loss_fn,epoch)\n",
        "    ls.append(eval_loss)\n",
        "    if (ls[-1]==min(ls)):\n",
        "          torch.save(pt_model.state_dict(), 'Poet_classification_Adam_finetune.pth')\n",
        "    eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "    \n",
        "    history['train_acc'].append(train_score['acc'])\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(eval_score['acc'])\n",
        "    history['val_loss'].append(eval_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-ZvVuRsoYRK"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRpWTfwdoWoS"
      },
      "source": [
        "test_poems = test['poem'].to_numpy()\n",
        "preds, probs = predict(pt_model, test_poems, tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "print(preds.shape, probs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRL2bgDDpUG0"
      },
      "source": [
        "y_test, y_pred = [poets.index(label) for label in test['poet'].values], list(preds)\n",
        "print(f'F1 score: {f1_score(y_test, y_pred, average=\"weighted\"):.4f}')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
        "loss_last = loss_fn(torch.tensor(probs),torch.tensor(y_test)).item()\n",
        "print(f'Loss: {loss_last}')\n",
        "print()\n",
        "print(classification_report(y_test, y_pred, target_names=poets))\n",
        "\n",
        "_, perple_loss = eval_op(pt_model, perplexity_data_loader, loss_fn,epoch)\n",
        "perplexity[1] = (torch.exp(torch.tensor(perple_loss)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm,display_labels=poets)\n",
        "fig, ax = plt.subplots(figsize=(20,20))\n",
        "ax.set_title('Confusion Matrix for The Test data',fontweight=\"bold\", size=40)\n",
        "ax.set_ylabel('YLabel',fontweight=\"bold\", fontsize = 20.0)\n",
        "ax.set_xlabel('XLabel',fontweight=\"bold\", fontsize = 20) \n",
        "disp.plot(ax=ax)\n"
      ],
      "metadata": {
        "id": "7iRv5zLo054P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART B2 :**\n",
        "Fine-tune whole model, by SGD algorithm"
      ],
      "metadata": {
        "id": "qxEV2nTPgvzd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4cawliVg6eZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "63230d25ad744a988cf9965fb261ac92",
            "05dc523b4ab94f90b1e4b69bb0037d48",
            "573b324f88434c139edd0adb520777ac",
            "8ed125a0d2f240848d58b6840d957aca",
            "76d59e0178eb4ece8947a7a0deb9b79e",
            "ab635322ce53412797b36048460419f5",
            "08735a619d8b497986974ad529ac4f25",
            "19728a2e6dec455d91284ca0790bd6a3",
            "68d84e9c5c8a4232a3f6bcd6d33cd092",
            "fc4c6f3b1b3742a68cd9ba11b9c4b3bb",
            "bf017f428d094ce6ad18265e42551048"
          ]
        },
        "outputId": "42ee6c7f-b333-4b59-b621-61a03e2404e1"
      },
      "source": [
        "pt_model = SentimentModel(config).to(device)\n",
        "print('pt_model', type(pt_model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63230d25ad744a988cf9965fb261ac92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_model <class '__main__.SentimentModel'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fplW-2r1g6eZ"
      },
      "source": [
        "sample_data_poem = sample_data['poem']\n",
        "sample_data_input_ids = sample_data['input_ids'].to(device)\n",
        "sample_data_attention_mask = sample_data['attention_mask'].to(device)\n",
        "sample_data_token_type_ids = sample_data['token_type_ids'].to(device)\n",
        "sample_data_targets = sample_data['targets'].to(device)\n",
        "\n",
        "outputs = pt_model(sample_data_input_ids, sample_data_attention_mask, sample_data_token_type_ids)\n",
        "_, preds = torch.max(outputs, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "LEARNING_RATE = 5e-4"
      ],
      "metadata": {
        "id": "o3nEWhRHg6ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "optimizer = torch.optim.SGD(pt_model.parameters(), lr=LEARNING_RATE,momentum = 0.9)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "eval_loss_min = np.Inf\n",
        "history = collections.defaultdict(list)"
      ],
      "metadata": {
        "id": "RutfSjje3V8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pt_model.load_state_dict(torch.load(\"Poet_classification_SGD_finetune.pth\"),strict = False)"
      ],
      "metadata": {
        "id": "vyWq1O0Kg6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a281a37c-95ad-4212-9162-0c4d3bcb84ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OULpRYwg6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af014d95-31d7-4a95-ddc0-3f6df0fce7bf"
      },
      "source": [
        "ls = []\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  \n",
        "    train_y, train_loss, eval_loss_min = train_op(pt_model, train_data_loader, loss_fn, optimizer, scheduler,epoch)\n",
        "\n",
        "    train_score = acc_and_f1(train_y[0], train_y[1], average='weighted')\n",
        "    \n",
        "    eval_y, eval_loss = eval_op(pt_model, valid_data_loader, loss_fn,epoch)\n",
        "    ls.append(eval_loss)\n",
        "    if (ls[-1]==min(ls)):\n",
        "          torch.save(pt_model.state_dict(), 'Poet_classification_SGD_finetune.pth')\n",
        "    eval_score = acc_and_f1(eval_y[0], eval_y[1], average='weighted')\n",
        "    \n",
        "    history['train_acc'].append(train_score['acc'])\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(eval_score['acc'])\n",
        "    history['val_loss'].append(eval_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "TRAIN EPOCH : 1 - Loss: 1.4223 - Accuracy: 49.74%: 100%|██████████| 2744/2744 [19:00<00:00,  2.41it/s]\n",
            "VALID EPOCH : 1 - Loss: 1.3399 - Accuracy: 52.97%: 100%|██████████| 305/305 [00:30<00:00,  9.88it/s]\n",
            "TRAIN EPOCH : 2 - Loss: 1.2989 - Accuracy: 54.30%:  83%|████████▎ | 2290/2744 [14:37<03:58,  1.90it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfF80LhZg6ea"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyaqoGpRg6ea"
      },
      "source": [
        "test_poems = test['poem'].to_numpy()\n",
        "preds, probs = predict(pt_model, test_poems, tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "print(preds.shape, probs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vh19CH3g6eb"
      },
      "source": [
        "y_test, y_pred = [poets.index(label) for label in test['poet'].values], list(preds)\n",
        "print(f'F1 score: {f1_score(y_test, y_pred, average=\"weighted\"):.4f}')\n",
        "print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\n",
        "loss_last = loss_fn(torch.tensor(probs),torch.tensor(y_test)).item()\n",
        "print(f'Loss: {loss_last}')\n",
        "print()\n",
        "print(classification_report(y_test, y_pred, target_names=poets))\n",
        "\n",
        "_, perple_loss = eval_op(pt_model, perplexity_data_loader, loss_fn,epoch)\n",
        "perplexity[2] = (torch.exp(torch.tensor(perple_loss)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(cm,display_labels=poets)\n",
        "fig, ax = plt.subplots(figsize=(20,20))\n",
        "ax.set_title('Confusion Matrix for The Test data',fontweight=\"bold\", size=40)\n",
        "ax.set_ylabel('YLabel',fontweight=\"bold\", fontsize = 20.0)\n",
        "ax.set_xlabel('XLabel',fontweight=\"bold\", fontsize = 20) \n",
        "disp.plot(ax=ax)\n"
      ],
      "metadata": {
        "id": "d9fZ5yYmg6eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART C**\n",
        "Calculate and show the Perplexity of the model before and after fine-tuning"
      ],
      "metadata": {
        "id": "8WMqX3em4GjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Perplexity of model before fine-tune: {perplexity[0]:.3f}')\n",
        "print(f'Perplexity of model after fine-tune by ADAM algorithm: {perplexity[1]:.3f}')\n",
        "print(f'Perplexity of model after fine-tune by SGD algorithm: {perplexity[2]:.3f}')"
      ],
      "metadata": {
        "id": "oS5Yr_Sz4UUB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}